{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit original tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\n",
    "Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "- torch: 0.4\n",
    "- torchvision\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1) # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1              # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64        # \n",
    "TIME_STEP  = 28        # rnn time step / image height\n",
    "INPUT_SIZE = 28        # rnn input size / image width\n",
    "LR = 0.01              # learning rate\n",
    "DOWNLOAD_MNIST=False    # set to True if haven't downloaded the data\n",
    "\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empty dir\n",
    "    DOWNLOAD_MNIST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',                  # \n",
    "    train=True,                       # this is training data\n",
    "    transform=transforms.ToTensor(),  # Converts a PIL.Image or numpy.ndarray to torch.FloatTensor of shape\n",
    "                                      # (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,          # download it if haven't\n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())   # [60000, 28, 28]\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "print(train_data.train_labels.size()) # [60000]\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\n",
    "test_y = test_data.test_labels.numpy()[:2000]    # covert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(   # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,   # rnn hidden unit\n",
    "            num_layers=1,     # number of rnn layer\n",
    "            batch_first=True, # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out = nn.Linear(64, 10)\n",
    "             \n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None) # `None` represents zero initial hidden state\n",
    "        \n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:         0 | step:         0 | train loss:    2.2874 | test accuracy:      0.10\n",
      "Epoch:         0 | step:        50 | train loss:    1.4017 | test accuracy:      0.41\n",
      "Epoch:         0 | step:       100 | train loss:    0.7916 | test accuracy:      0.60\n",
      "Epoch:         0 | step:       150 | train loss:    0.7277 | test accuracy:      0.71\n",
      "Epoch:         0 | step:       200 | train loss:    0.8641 | test accuracy:      0.76\n",
      "Epoch:         0 | step:       250 | train loss:    0.4838 | test accuracy:      0.82\n",
      "Epoch:         0 | step:       300 | train loss:    0.5030 | test accuracy:      0.85\n",
      "Epoch:         0 | step:       350 | train loss:    0.4434 | test accuracy:      0.88\n",
      "Epoch:         0 | step:       400 | train loss:    0.1966 | test accuracy:      0.87\n",
      "Epoch:         0 | step:       450 | train loss:    0.2843 | test accuracy:      0.87\n",
      "Epoch:         0 | step:       500 | train loss:    0.1115 | test accuracy:      0.87\n",
      "Epoch:         0 | step:       550 | train loss:    0.4247 | test accuracy:      0.92\n",
      "Epoch:         0 | step:       600 | train loss:    0.2240 | test accuracy:      0.91\n",
      "Epoch:         0 | step:       650 | train loss:    0.3937 | test accuracy:      0.90\n",
      "Epoch:         0 | step:       700 | train loss:    0.6917 | test accuracy:      0.90\n",
      "Epoch:         0 | step:       750 | train loss:    0.1306 | test accuracy:      0.93\n",
      "Epoch:         0 | step:       800 | train loss:    0.2675 | test accuracy:      0.92\n",
      "Epoch:         0 | step:       850 | train loss:    0.1734 | test accuracy:      0.93\n",
      "Epoch:         0 | step:       900 | train loss:    0.1080 | test accuracy:      0.93\n",
      "Epoch:         0 | step:       950 | train loss:    0.1897 | test accuracy:      0.94\n",
      "Epoch:         0 | step:      1000 | train loss:    0.1060 | test accuracy:      0.92\n",
      "Epoch:         0 | step:      1050 | train loss:    0.1903 | test accuracy:      0.94\n",
      "Epoch:         0 | step:      1100 | train loss:    0.4343 | test accuracy:      0.94\n",
      "Epoch:         0 | step:      1150 | train loss:    0.5305 | test accuracy:      0.93\n",
      "Epoch:         0 | step:      1200 | train loss:    0.0352 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1250 | train loss:    0.0334 | test accuracy:      0.94\n",
      "Epoch:         0 | step:      1300 | train loss:    0.1687 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1350 | train loss:    0.2610 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1400 | train loss:    0.4834 | test accuracy:      0.93\n",
      "Epoch:         0 | step:      1450 | train loss:    0.0992 | test accuracy:      0.94\n",
      "Epoch:         0 | step:      1500 | train loss:    0.1118 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1550 | train loss:    0.2205 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1600 | train loss:    0.0606 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1650 | train loss:    0.1018 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1700 | train loss:    0.1210 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1750 | train loss:    0.4791 | test accuracy:      0.94\n",
      "Epoch:         0 | step:      1800 | train loss:    0.3304 | test accuracy:      0.95\n",
      "Epoch:         0 | step:      1850 | train loss:    0.0921 | test accuracy:      0.95\n",
      "[7 2 1 0 4 1 4 9 4 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr = LR) # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):  # gives batch data\n",
    "        b_x = b_x.view(-1, 28, 28) # reshape x to (batch, time_step, input_size)\n",
    "        \n",
    "        output=rnn(b_x)                # rnn output\n",
    "        loss = loss_func(output, b_y)  # cross entropy loss\n",
    "        optimizer.zero_grad()          # clear gradients for this training step\n",
    "        loss.backward()                # backpropagation, compute gradients\n",
    "        optimizer.step()               # apply gradients\n",
    "        \n",
    "        if step%50==0:\n",
    "            test_output = rnn(test_x)  # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y==test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: %9.0f' % epoch, \n",
    "                  '| step: %9.0f' % step, \n",
    "                  '| train loss: %9.4f' % loss.data.numpy(), \n",
    "                  '| test accuracy: %9.2f' % accuracy)\n",
    "        \n",
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
