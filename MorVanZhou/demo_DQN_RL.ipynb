{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "More about Reinforcement learning: https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/\n",
    "\n",
    "Dependencies:\n",
    "- torch: 0.4\n",
    "- gym: 0.8.1\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install\n",
    "pip install gym\n",
    "## Render Requirements:\n",
    "\n",
    "sudo apt install xvfb\n",
    "sudo apt install python-opengl\n",
    "## Render to jupyter:\n",
    "\n",
    "pip install jupyter\n",
    "xvfb-run -s \"-screen 0 600x400x24\" jupyter-notebook Render-matplotlib.ipynb  \n",
    "## Render to MP4:\n",
    "\n",
    "sudo apt install ffmpeg\n",
    "xvfb-run -s \"-screen 0 600x400x24\" python RenderToMP4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# show state\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.01                   # learning rate\n",
    "EPSILON = 0.9               # greedy policy\n",
    "GAMMA = 0.9                 # reward discount\n",
    "TARGET_REPLACE_ITER = 100   # target update frequency\n",
    "MEMORY_CAPACITY = 2000\n",
    "env = gym.make('CartPole-v0')\n",
    "env = env.unwrapped\n",
    "N_ACTIONS = env.action_space.n\n",
    "N_STATES = env.observation_space.shape[0]\n",
    "# to confirm the shape\n",
    "ENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gym\n",
    "# %matplotlib inline\n",
    "\n",
    "# env = gym.make('CartPole-v0')\n",
    "# env.reset()\n",
    "# img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "# for _ in range(100):\n",
    "#     img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "#     display.display(plt.gcf())\n",
    "#     display.clear_output(wait=True)\n",
    "#     action = env.action_space.sample()\n",
    "#     env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES, 50)\n",
    "        self.fc1.weight.data.normal_(0, 0.1)   # initialization\n",
    "        self.out = nn.Linear(50, N_ACTIONS)\n",
    "        self.out.weight.data.normal_(0, 0.1)   # initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        actions_value = self.out(x)\n",
    "        return actions_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "\n",
    "        self.learn_step_counter = 0                                     # for target updating\n",
    "        self.memory_counter = 0                                         # for storing memory\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        q_next = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)   # shape (batch, 1)\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DISPLAY=localhost:0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (env.spec.id,step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    \n",
    "dqn = DQN()\n",
    "\n",
    "print('\\nCollecting experience...')\n",
    "for i_episode in range(400):\n",
    "    s = env.reset()\n",
    "    ep_r = 0\n",
    "    while True:\n",
    "        env.render()     \n",
    "        a = dqn.choose_action(s)\n",
    "        \n",
    "        show_state(env, i_episode, \"\")   \n",
    "\n",
    "        # take action\n",
    "        s_, r, done, info = env.step(a)\n",
    "\n",
    "        # modify the reward\n",
    "        x, x_dot, theta, theta_dot = s_\n",
    "        r1 = (env.x_threshold - abs(x)) / env.x_threshold - 0.8\n",
    "        r2 = (env.theta_threshold_radians - abs(theta)) / env.theta_threshold_radians - 0.5\n",
    "        r = r1 + r2\n",
    "\n",
    "        dqn.store_transition(s, a, r, s_)\n",
    "\n",
    "        ep_r += r\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "            if done:\n",
    "                print('Ep: ', i_episode,\n",
    "                      '| Ep_r: ', round(ep_r, 2))\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "        s = s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
