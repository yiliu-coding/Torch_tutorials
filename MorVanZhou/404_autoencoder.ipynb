{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit original tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\n",
    "Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "- torch: 0.4\n",
    "- torchvision\n",
    "- matplotlib\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)   # reproducible\n",
    "\n",
    "# Hyper parameters\n",
    "EPOCH = 20\n",
    "BATCH_SIZE=  64\n",
    "LR = 0.005\n",
    "DOWNLOAD_MNIST= False\n",
    "N_TEST_IMG = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empty dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "    \n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = './mnist/', \n",
    "    train=True,                                  # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(), # Converts a PIL.Image or numpy.ndarray to\n",
    "                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,\n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())    # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())  # (60000)\n",
    "plt.imshow(train_data.train_data[2].data.numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[2])\n",
    "plt.show()\n",
    "\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12,3), #  compress to 3 features which can be visualized in plt\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12,64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid(), # compress to a range (0,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0 | train loss: 0.2301\n",
      "Epoch:    0 | train loss: 0.0702\n",
      "Epoch:    0 | train loss: 0.0612\n",
      "Epoch:    0 | train loss: 0.0572\n",
      "Epoch:    0 | train loss: 0.0587\n",
      "Epoch:    0 | train loss: 0.0522\n",
      "Epoch:    0 | train loss: 0.0511\n",
      "Epoch:    0 | train loss: 0.0499\n",
      "Epoch:    0 | train loss: 0.0502\n",
      "Epoch:    0 | train loss: 0.0443\n",
      "Epoch:    1 | train loss: 0.0478\n",
      "Epoch:    1 | train loss: 0.0455\n",
      "Epoch:    1 | train loss: 0.0442\n",
      "Epoch:    1 | train loss: 0.0421\n",
      "Epoch:    1 | train loss: 0.0450\n",
      "Epoch:    1 | train loss: 0.0427\n",
      "Epoch:    1 | train loss: 0.0433\n",
      "Epoch:    1 | train loss: 0.0445\n",
      "Epoch:    1 | train loss: 0.0436\n",
      "Epoch:    1 | train loss: 0.0452\n",
      "Epoch:    2 | train loss: 0.0422\n",
      "Epoch:    2 | train loss: 0.0424\n",
      "Epoch:    2 | train loss: 0.0406\n",
      "Epoch:    2 | train loss: 0.0417\n",
      "Epoch:    2 | train loss: 0.0449\n",
      "Epoch:    2 | train loss: 0.0410\n",
      "Epoch:    2 | train loss: 0.0429\n",
      "Epoch:    2 | train loss: 0.0428\n",
      "Epoch:    2 | train loss: 0.0440\n",
      "Epoch:    2 | train loss: 0.0400\n",
      "Epoch:    3 | train loss: 0.0487\n",
      "Epoch:    3 | train loss: 0.0392\n",
      "Epoch:    3 | train loss: 0.0431\n",
      "Epoch:    3 | train loss: 0.0433\n",
      "Epoch:    3 | train loss: 0.0387\n",
      "Epoch:    3 | train loss: 0.0427\n",
      "Epoch:    3 | train loss: 0.0434\n",
      "Epoch:    3 | train loss: 0.0416\n",
      "Epoch:    3 | train loss: 0.0413\n",
      "Epoch:    3 | train loss: 0.0431\n",
      "Epoch:    4 | train loss: 0.0399\n",
      "Epoch:    4 | train loss: 0.0417\n",
      "Epoch:    4 | train loss: 0.0406\n",
      "Epoch:    4 | train loss: 0.0402\n",
      "Epoch:    4 | train loss: 0.0428\n",
      "Epoch:    4 | train loss: 0.0433\n",
      "Epoch:    4 | train loss: 0.0389\n",
      "Epoch:    4 | train loss: 0.0419\n",
      "Epoch:    4 | train loss: 0.0453\n",
      "Epoch:    4 | train loss: 0.0384\n",
      "Epoch:    5 | train loss: 0.0420\n",
      "Epoch:    5 | train loss: 0.0379\n",
      "Epoch:    5 | train loss: 0.0428\n",
      "Epoch:    5 | train loss: 0.0413\n",
      "Epoch:    5 | train loss: 0.0431\n",
      "Epoch:    5 | train loss: 0.0404\n",
      "Epoch:    5 | train loss: 0.0409\n",
      "Epoch:    5 | train loss: 0.0412\n",
      "Epoch:    5 | train loss: 0.0425\n",
      "Epoch:    9 | train loss: 0.0437\n",
      "Epoch:    9 | train loss: 0.0409\n",
      "Epoch:    9 | train loss: 0.0401\n",
      "Epoch:    9 | train loss: 0.0399\n",
      "Epoch:    9 | train loss: 0.0438\n",
      "Epoch:    9 | train loss: 0.0413\n",
      "Epoch:    9 | train loss: 0.0390\n",
      "Epoch:   10 | train loss: 0.0423\n",
      "Epoch:   10 | train loss: 0.0381\n",
      "Epoch:   10 | train loss: 0.0421\n",
      "Epoch:   10 | train loss: 0.0352\n",
      "Epoch:   10 | train loss: 0.0464\n",
      "Epoch:   10 | train loss: 0.0384\n",
      "Epoch:   10 | train loss: 0.0410\n",
      "Epoch:   10 | train loss: 0.0381\n",
      "Epoch:   10 | train loss: 0.0405\n",
      "Epoch:   10 | train loss: 0.0401\n",
      "Epoch:   11 | train loss: 0.0381\n",
      "Epoch:   11 | train loss: 0.0411\n",
      "Epoch:   11 | train loss: 0.0394\n",
      "Epoch:   11 | train loss: 0.0379\n",
      "Epoch:   11 | train loss: 0.0398\n",
      "Epoch:   11 | train loss: 0.0408\n",
      "Epoch:   11 | train loss: 0.0392\n",
      "Epoch:   11 | train loss: 0.0390\n",
      "Epoch:   11 | train loss: 0.0393\n",
      "Epoch:   11 | train loss: 0.0431\n",
      "Epoch:   12 | train loss: 0.0350\n",
      "Epoch:   12 | train loss: 0.0388\n",
      "Epoch:   12 | train loss: 0.0420\n",
      "Epoch:   12 | train loss: 0.0376\n",
      "Epoch:   12 | train loss: 0.0400\n",
      "Epoch:   12 | train loss: 0.0358\n",
      "Epoch:   12 | train loss: 0.0404\n",
      "Epoch:   12 | train loss: 0.0375\n",
      "Epoch:   12 | train loss: 0.0358\n",
      "Epoch:   12 | train loss: 0.0416\n",
      "Epoch:   13 | train loss: 0.0415\n",
      "Epoch:   13 | train loss: 0.0381\n",
      "Epoch:   13 | train loss: 0.0369\n",
      "Epoch:   13 | train loss: 0.0415\n",
      "Epoch:   13 | train loss: 0.0382\n",
      "Epoch:   13 | train loss: 0.0360\n",
      "Epoch:   13 | train loss: 0.0402\n",
      "Epoch:   13 | train loss: 0.0390\n",
      "Epoch:   13 | train loss: 0.0392\n",
      "Epoch:   13 | train loss: 0.0384\n",
      "Epoch:   14 | train loss: 0.0385\n",
      "Epoch:   14 | train loss: 0.0414\n",
      "Epoch:   14 | train loss: 0.0360\n",
      "Epoch:   14 | train loss: 0.0319\n",
      "Epoch:   14 | train loss: 0.0384\n",
      "Epoch:   14 | train loss: 0.0402\n",
      "Epoch:   14 | train loss: 0.0387\n",
      "Epoch:   14 | train loss: 0.0383\n",
      "Epoch:   14 | train loss: 0.0389\n",
      "Epoch:   14 | train loss: 0.0353\n"
     ]
    }
   ],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr = LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# initialize figure\n",
    "f, a = plt.subplots(2, N_TEST_IMG, figsize=(5,2))\n",
    "plt.ion() # continuously plot\n",
    "\n",
    "f.canvas.draw()\n",
    "# original data (first row) for viewing\n",
    "view_data = train_data.train_data[:N_TEST_IMG].view(-1, 28,28).type(torch.FloatTensor)/255.0\n",
    "for i in range(N_TEST_IMG):\n",
    "    a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "    a[0][i].set_xticks(())\n",
    "    a[0][i].set_yticks(())\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, b_label) in enumerate(train_loader):\n",
    "        b_x = x.view(-1, 28,28)   # batch x, shape (batch, 28*28)\n",
    "        b_y = x.view(-1, 28,28)   # batch x, shape (batch, 28*28)\n",
    "        \n",
    "        encoded, decoded = autoencoder(b_x.view(-1, 28*28))\n",
    "        \n",
    "        loss = loss_func(decoded, b_y.view(-1, 28*28)) # mean square error - MSELoss\n",
    "        optimizer.zero_grad()          # clear gradients for this training step\n",
    "        loss.backward()                # backpropagation, calculate gradients\n",
    "        optimizer.step()               # apply the gradients from above line\n",
    "        \n",
    "        if step%100 == 0:\n",
    "            print('Epoch: %4.0i' % epoch, '| train loss: %6.4f' % loss.data.numpy())\n",
    "            \n",
    "            # plotting decoded image (second row)\n",
    "            _, decoded_data = autoencoder(view_data.view(-1, 28*28))\n",
    "            for i in range (N_TEST_IMG):\n",
    "                a[1][i].clear()\n",
    "                a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i],(28,28)), cmap='gray' )\n",
    "                a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "            f.canvas.draw(); # plt.pause(0.05)\n",
    "plt.ioff()\n",
    "# plt.show()\n",
    "view_data = train_data.train_data[:200].view(-1, 28*28).type(torch.FloatTensor)/255.0\n",
    "encoder_data, _ = autoencoder(view_data)\n",
    "\n",
    "fig = plt.figure(2); ax = Axes3D(fig)\n",
    "X,Y,Z=encoder_data.data[:,0].numpy(), encoder_data.data[:,1].numpy(), encoder_data.data[:,2].numpy()\n",
    "values = train_data.train_labels[:200].numpy()\n",
    "\n",
    "for x, y, z, s in zip (X, Y, Z, values):\n",
    "    c=cm.rainbow(int(255*s/9)); ax.text(x, y, z, s, backgroundcolor=c)\n",
    "ax.set_xlim(X.min(), X.max()); ax.set_ylim(Y.min(), Y.max()); ax.set_zlim(Z.min(), Z.max())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (N_TEST_IMG):\n",
    "    a[1][i].clear()\n",
    "    a[1][i].imshow(np.reshape(decoded_data.zero_().data.numpy()[i],(28,28)), cmap='gray' )\n",
    "    a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "f.canvas.draw();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
