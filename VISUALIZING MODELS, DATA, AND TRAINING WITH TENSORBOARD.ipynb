{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# VISUALIZING MODELS, DATA, AND TRAINING WITH TENSORBOARD\n",
    "In the [60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), we show you how to load in data, feed it through a model we define as a subclass of nn.Module, train this model on training data, and test it on test data. To see what’s happening, we print out some statistics as the model is training to get a sense for whether training is progressing. However, we can do much better than that: PyTorch integrates with TensorBoard, a tool designed for visualizing the results of neural network training runs. This tutorial illustrates some of its functionality, using the Fashion-MNIST dataset which can be read into PyTorch using torchvision.datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "                #         mean      std, one value since there's only one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img=img.mean(dim=0)\n",
    "    img=img/2+0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap='Greys')\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We’ll define a similar model architecture from that tutorial, making only minor modifications to account for the fact that the images are now one channel instead of three and 28x28 instead of 32x32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # in_channel_number, out_channel_number, conv kernel size, \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll define the same optimizer and criterion from before:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorBoard setup\n",
    "Now we’ll set up TensorBoard, importing tensorboard from torch.utils and defining a SummaryWriter, our key object for writing information to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "# Note that this line alone creates a runs/fashion_mnist_experiment_1 folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing to TensorBoard\n",
    "Now let’s write an image to our TensorBoard - specifically, a grid - using make_grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now running\n",
    "# # tensorboard --logdir=runs\n",
    "# import datetime, os\n",
    "\n",
    "# logs_base_dir = \"./logs\"\n",
    "# os.makedirs(logs_base_dir, exist_ok=True)\n",
    "\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# # tensorboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect the model using TensorBoard\n",
    "One of TensorBoard’s strengths is its ability to visualize complex model structures. Let’s visualize the model we built.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://pallas.imr.no:5555/#graphs&run=.\">text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now upon refreshing TensorBoard you should see a “Graphs” tab that looks like this\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"<a href=\"http://pallas.imr.no:5555/#graphs&run=.\">text</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Go ahead and double click on “Net” to see it expand, seeing a detailed view of the individual operations that make up the model.\n",
    "\n",
    "TensorBoard has a very handy feature for visualizing high dimensional data such as image data in a lower dimensional space; we’ll cover this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a “Projector” to TensorBoard\n",
    "We can visualize the lower dimensional representation of higher dimensional data via the add_embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random dapapoints and thei corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28*28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ve thoroughly inspected our data, let’s show how TensorBoard can make tracking model training and evaluation clearer, starting with training.\n",
    "\n",
    "## 5. Tracking model training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and correspondin proabilisties from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this information \n",
    "    based on whether the prediction was correct or not. \n",
    "    Use the \"images_to_prob\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1,4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx]*100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
